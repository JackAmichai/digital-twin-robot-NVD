# =============================================================================
# Digital Twin Robotics Lab - Environment Configuration
# =============================================================================
# Copy this file to .env and customize for your setup
# =============================================================================

# -----------------------------------------------------------------------------
# NVIDIA Configuration
# -----------------------------------------------------------------------------
# Your NGC API Key (get from https://ngc.nvidia.com/)
NGC_API_KEY=your_ngc_api_key_here

# CUDA Version (should match your driver)
CUDA_VERSION=12.2

# -----------------------------------------------------------------------------
# ROS 2 Configuration
# -----------------------------------------------------------------------------
# ROS Domain ID (0-232, use different IDs for different robots/networks)
ROS_DOMAIN_ID=0

# ROS Middleware (fastrtps recommended for Isaac Sim compatibility)
RMW_IMPLEMENTATION=rmw_fastrtps_cpp

# Log level (DEBUG, INFO, WARN, ERROR, FATAL)
RCUTILS_LOGGING_SEVERITY_THRESHOLD=INFO

# -----------------------------------------------------------------------------
# Isaac Sim Configuration
# -----------------------------------------------------------------------------
# Accept NVIDIA EULA (required)
ACCEPT_EULA=Y

# Privacy consent for telemetry
PRIVACY_CONSENT=Y

# Headless mode (set to 1 for server/CI environments)
HEADLESS=0

# Streaming quality (low, medium, high, ultra)
STREAMING_QUALITY=high

# -----------------------------------------------------------------------------
# Cognitive Service Configuration
# -----------------------------------------------------------------------------
# LLM Provider (nim, ollama, openai)
LLM_PROVIDER=nim

# NVIDIA NIM API endpoint
NIM_API_ENDPOINT=https://integrate.api.nvidia.com/v1

# NVIDIA NIM API Key
NIM_API_KEY=your_nim_api_key_here

# LLM Model to use
LLM_MODEL=meta/llama-3.1-8b-instruct

# Ollama host (if using Ollama)
OLLAMA_HOST=http://host.docker.internal:11434

# -----------------------------------------------------------------------------
# Riva ASR Configuration
# -----------------------------------------------------------------------------
# Riva server address
RIVA_SERVER=localhost:50051

# ASR language
RIVA_ASR_LANGUAGE=en-US

# Enable profanity filter
RIVA_PROFANITY_FILTER=true

# -----------------------------------------------------------------------------
# Development Settings
# -----------------------------------------------------------------------------
# Display for GUI applications (Linux/WSL)
DISPLAY=:0

# Enable debug mode
DEBUG=false

# Log directory
LOG_DIR=./logs

# -----------------------------------------------------------------------------
# Network Configuration
# -----------------------------------------------------------------------------
# Host IP (for external connections)
HOST_IP=127.0.0.1

# Foxglove bridge port
FOXGLOVE_PORT=8765

# Redis connection
REDIS_URL=redis://redis:6379

# -----------------------------------------------------------------------------
# Resource Limits
# -----------------------------------------------------------------------------
# Max GPU memory fraction (0.0-1.0)
GPU_MEMORY_FRACTION=0.8

# CPU cores limit
CPU_LIMIT=8

# Memory limit
MEMORY_LIMIT=32g
